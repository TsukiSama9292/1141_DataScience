"""
å¯¦é©—å ±å‘Šç”Ÿæˆå™¨

æ•´åˆåˆ†æã€å¯è¦–åŒ–å’Œæ–‡æª”ç”ŸæˆåŠŸèƒ½ï¼Œç”¢ç”Ÿå®Œæ•´çš„å¯¦é©—å ±å‘Š
"""

import json
from pathlib import Path
from typing import Dict, Any
import matplotlib.pyplot as plt
import matplotlib
import numpy as np

from .analysis import ExperimentAnalyzer, DatasetAnalyzer

# è¨­ç½®ä¸­æ–‡å­—é«”
matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False


class ReportGenerator:
    """å¯¦é©—å ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, analyzer: ExperimentAnalyzer = None, 
                 dataset_analyzer: DatasetAnalyzer = None,
                 output_dir: str = 'reports',
                 dataset_size: str = None):
        """
        Args:
            analyzer: å¯¦é©—åˆ†æå™¨
            dataset_analyzer: è³‡æ–™é›†åˆ†æå™¨
            output_dir: è¼¸å‡ºç›®éŒ„
            dataset_size: è³‡æ–™é›†å¤§å°æ¨™è­˜ ('full' æˆ–æ•¸å­—å¦‚ '100000')
        """
        self.analyzer = analyzer or ExperimentAnalyzer()
        self.dataset_analyzer = dataset_analyzer or DatasetAnalyzer()
        self.output_dir = Path(output_dir)
        self.figures_dir = self.output_dir / 'figures'
        self.figures_dir.mkdir(parents=True, exist_ok=True)
        self.dataset_size = dataset_size  # ç”¨æ–¼æ–‡ä»¶å‘½å
    
    def _load_grid_results(self):
        """è¼‰å…¥ SVD_KNN_GRID ç¶²æ ¼æœç´¢çµæœ"""
        log_dir = Path('log')
        grid_results = []
        
        # è¼‰å…¥æ‰€æœ‰ SVD_KNN_GRID çµæœ (1-100)
        for i in range(1, 101):
            config_name = f'SVD_KNN_GRID_{i:03d}'
            json_file = log_dir / f'{config_name}.json'
            
            if json_file.exists():
                try:
                    with open(json_file, 'r') as f:
                        data = json.load(f)
                    
                    # å¾é…ç½®ä¸­è®€å–å¯¦éš›çš„åƒæ•¸å€¼
                    config = data.get('config', {})
                    n_components = config.get('n_components')
                    k_neighbors = config.get('k_neighbors')
                    
                    # è·³éç„¡æ•ˆé…ç½®
                    if n_components is None or k_neighbors is None:
                        continue
                    
                    metrics = data.get('metrics', {})
                    time_records = data.get('time_records', {})
                    
                    grid_results.append({
                        'config_name': config_name,
                        'n_components': n_components,
                        'k_neighbors': k_neighbors,
                        'hit_rate': metrics.get('hit_rate', 0),
                        'ndcg': metrics.get('ndcg', 0),
                        'rmse': metrics.get('rmse', 0),
                        'total_time': sum(time_records.values()) if time_records else 0
                    })
                except Exception as e:
                    print(f"âš ï¸ ç„¡æ³•è®€å– {json_file}: {e}")
        
        return grid_results
    
    def _load_expand_results(self):
        """è¼‰å…¥ SVD_KNN_EXPAND ç¶²æ ¼æœç´¢çµæœ"""
        log_dir = Path('log')
        expand_results = []
        
        # è¼‰å…¥æ‰€æœ‰ SVD_KNN_EXPAND çµæœ (1-36)
        for i in range(1, 37):
            config_name = f'SVD_KNN_EXPAND_{i:03d}'
            json_file = log_dir / f'{config_name}.json'
            
            if json_file.exists():
                try:
                    with open(json_file, 'r') as f:
                        data = json.load(f)
                    
                    # å¾é…ç½®ä¸­è®€å–å¯¦éš›çš„åƒæ•¸å€¼
                    config = data.get('config', {})
                    n_components = config.get('n_components')
                    k_neighbors = config.get('k_neighbors')
                    
                    # è·³éç„¡æ•ˆé…ç½®
                    if n_components is None or k_neighbors is None:
                        continue
                    
                    metrics = data.get('metrics', {})
                    time_records = data.get('time_records', {})
                    
                    expand_results.append({
                        'config_name': config_name,
                        'n_components': n_components,
                        'k_neighbors': k_neighbors,
                        'hit_rate': metrics.get('hit_rate', 0),
                        'ndcg': metrics.get('ndcg', 0),
                        'rmse': metrics.get('rmse', 0),
                        'total_time': sum(time_records.values()) if time_records else 0
                    })
                except Exception as e:
                    print(f"âš ï¸ ç„¡æ³•è®€å– {json_file}: {e}")
        
        return expand_results
    
    def _load_knn_baseline_results(self):
        """è¼‰å…¥ KNN_BASELINE ç´”KNNåŸºæº–ç·šçµæœ"""
        log_dir = Path('log')
        baseline_results = []
        
        # è¼‰å…¥æ‰€æœ‰ KNN_BASELINE çµæœ (1-10)
        for i in range(1, 11):
            config_name = f'KNN_BASELINE_{i:03d}'
            json_file = log_dir / f'{config_name}.json'
            
            if json_file.exists():
                try:
                    with open(json_file, 'r') as f:
                        data = json.load(f)
                    
                    # å¾é…ç½®ä¸­è®€å–å¯¦éš›çš„ k_neighbors å€¼
                    config = data.get('config', {})
                    k_neighbors = config.get('k_neighbors', 5 * i)  # fallback to 5*i
                    
                    metrics = data.get('metrics', {})
                    time_records = data.get('time_records', {})
                    
                    baseline_results.append({
                        'config_name': config_name,
                        'k_neighbors': k_neighbors,
                        'hit_rate': metrics.get('hit_rate', 0),
                        'ndcg': metrics.get('ndcg', 0),
                        'rmse': metrics.get('rmse', 0),
                        'total_time': sum(time_records.values()) if time_records else 0
                    })
                except Exception as e:
                    print(f"âš ï¸ ç„¡æ³•è®€å– {json_file}: {e}")
        
        return baseline_results
    
    def generate_svd_plots(self) -> bool:
        """ç”Ÿæˆ SVD ç¶­åº¦åˆ†æåœ–ï¼ˆå¾ç¶²æ ¼æœç´¢çµæœæå–ï¼‰"""
        # å¾ SVD_KNN_GRID çµæœä¸­æå– SVD åˆ†ææ•¸æ“š
        grid_results = self._load_grid_results()
        
        if not grid_results:
            print("âš ï¸ SVD_KNN_GRID çµæœä¸è¶³ï¼Œè·³éåœ–è¡¨ç”Ÿæˆ")
            return False
        
        # æŒ‰ SVD ç¶­åº¦åˆ†çµ„ï¼Œå°æ¯å€‹ç¶­åº¦å–æ‰€æœ‰ K å€¼çš„å¹³å‡
        svd_analysis = {}
        for result in grid_results:
            dim = result['n_components']
            if dim not in svd_analysis:
                svd_analysis[dim] = {'hit_rates': [], 'ndcgs': [], 'rmses': [], 'times': []}
            
            svd_analysis[dim]['hit_rates'].append(result['hit_rate'])
            svd_analysis[dim]['ndcgs'].append(result['ndcg'])
            svd_analysis[dim]['rmses'].append(result['rmse'])
            svd_analysis[dim]['times'].append(result['total_time'])
        
        # è¨ˆç®—å¹³å‡å€¼
        dims = sorted(svd_analysis.keys())
        hit_rates = [np.mean(svd_analysis[d]['hit_rates']) for d in dims]
        ndcgs = [np.mean(svd_analysis[d]['ndcgs']) for d in dims]
        rmses = [np.mean(svd_analysis[d]['rmses']) for d in dims]
        times = [np.mean(svd_analysis[d]['times']) for d in dims]
        
        # å‰µå»ºåœ–è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('SVD Dimension Analysis', fontsize=16, fontweight='bold')
        
        # 1. Hit Rate vs Dimension
        ax1.plot(dims, hit_rates, 'o-', linewidth=2, markersize=8, color='#2E86AB')
        ax1.set_xlabel('SVD Dimension', fontsize=12)
        ax1.set_ylabel('Hit Rate@10', fontsize=12)
        ax1.set_title('Hit Rate@10 vs SVD Dimension', fontsize=14, fontweight='bold')
        ax1.set_xscale('log', base=2)  # ä½¿ç”¨å°æ•¸åˆ»åº¦ï¼Œå› ç‚ºç¶­åº¦æ˜¯ 2^N
        ax1.grid(True, alpha=0.3)
        
        if hit_rates:
            best_hit_rate = max(hit_rates)
            best_idx = hit_rates.index(best_hit_rate)
            ax1.axhline(y=best_hit_rate, color='r', linestyle='--', alpha=0.5, 
                       label=f'Best: {best_hit_rate:.4f}')
            ax1.plot(dims[best_idx], hit_rates[best_idx], 'r*', markersize=20, 
                    label=f'Best Dim: {dims[best_idx]}')
            ax1.legend()
        
        # 2. NDCG vs Dimension
        ax2.plot(dims, ndcgs, 'o-', linewidth=2, markersize=8, color='#F18F01')
        ax2.set_xlabel('SVD Dimension', fontsize=12)
        ax2.set_ylabel('NDCG@10', fontsize=12)
        ax2.set_title('NDCG@10 vs SVD Dimension', fontsize=14, fontweight='bold')
        ax2.set_xscale('log', base=2)  # ä½¿ç”¨å°æ•¸åˆ»åº¦
        ax2.grid(True, alpha=0.3)
        
        # 3. RMSE vs Dimension
        ax3.plot(dims, rmses, 'o-', linewidth=2, markersize=8, color='#C73E1D')
        ax3.set_xlabel('SVD Dimension', fontsize=12)
        ax3.set_ylabel('RMSE', fontsize=12)
        ax3.set_title('RMSE vs SVD Dimension', fontsize=14, fontweight='bold')
        ax3.set_xscale('log', base=2)  # ä½¿ç”¨å°æ•¸åˆ»åº¦
        ax3.grid(True, alpha=0.3)
        
        # 4. Execution Time vs Dimension
        ax4.plot(dims, times, 'o-', linewidth=2, markersize=8, color='#6A994E')
        ax4.set_xlabel('SVD Dimension', fontsize=12)
        ax4.set_ylabel('Execution Time (seconds)', fontsize=12)
        ax4.set_title('Execution Time vs SVD Dimension', fontsize=14, fontweight='bold')
        ax4.set_xscale('log', base=2)  # ä½¿ç”¨å°æ•¸åˆ»åº¦
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        output_path = self.figures_dir / 'svd_dimension_analysis.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… SVD åˆ†æåœ–å·²ä¿å­˜: {output_path}")
        return True
    
    def generate_knn_plots(self) -> bool:
        """ç”Ÿæˆ KNN Kå€¼åˆ†æåœ–ï¼ˆå¾ç¶²æ ¼æœç´¢çµæœæå–ï¼‰"""
        # å¾ SVD_KNN_GRID çµæœä¸­æå– KNN åˆ†ææ•¸æ“š
        grid_results = self._load_grid_results()
        
        if not grid_results:
            print("âš ï¸ SVD_KNN_GRID çµæœä¸è¶³ï¼Œè·³éåœ–è¡¨ç”Ÿæˆ")
            return False
        
        # æŒ‰ K å€¼åˆ†çµ„ï¼Œå°æ¯å€‹ K å€¼å–æ‰€æœ‰ SVD ç¶­åº¦çš„å¹³å‡
        knn_analysis = {}
        for result in grid_results:
            k = result['k_neighbors']
            if k not in knn_analysis:
                knn_analysis[k] = {'hit_rates': [], 'ndcgs': [], 'rmses': [], 'times': []}
            
            knn_analysis[k]['hit_rates'].append(result['hit_rate'])
            knn_analysis[k]['ndcgs'].append(result['ndcg'])
            knn_analysis[k]['rmses'].append(result['rmse'])
            knn_analysis[k]['times'].append(result['total_time'])
        
        # è¨ˆç®—å¹³å‡å€¼
        ks = sorted(knn_analysis.keys())
        hit_rates = [np.mean(knn_analysis[k]['hit_rates']) for k in ks]
        ndcgs = [np.mean(knn_analysis[k]['ndcgs']) for k in ks]
        rmses = [np.mean(knn_analysis[k]['rmses']) for k in ks]
        times = [np.mean(knn_analysis[k]['times']) for k in ks]
        
        # å‰µå»ºåœ–è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('KNN K-value Analysis', fontsize=16, fontweight='bold')
        
        # 1. Hit Rate vs K
        ax1.plot(ks, hit_rates, 'o-', linewidth=2, markersize=8, color='#2E86AB')
        ax1.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax1.set_ylabel('Hit Rate@10', fontsize=12)
        ax1.set_title('Hit Rate@10 vs K', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        
        if hit_rates:
            best_hit_rate = max(hit_rates)
            best_idx = hit_rates.index(best_hit_rate)
            ax1.axhline(y=best_hit_rate, color='r', linestyle='--', alpha=0.5, 
                       label=f'Best: {best_hit_rate:.4f}')
            ax1.plot(ks[best_idx], hit_rates[best_idx], 'r*', markersize=20, 
                    label=f'Best K: {ks[best_idx]}')
            ax1.legend()
        
        # 2. NDCG vs K
        ax2.plot(ks, ndcgs, 'o-', linewidth=2, markersize=8, color='#F18F01')
        ax2.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax2.set_ylabel('NDCG@10', fontsize=12)
        ax2.set_title('NDCG@10 vs K', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        
        # 3. RMSE vs K
        ax3.plot(ks, rmses, 'o-', linewidth=2, markersize=8, color='#C73E1D')
        ax3.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax3.set_ylabel('RMSE', fontsize=12)
        ax3.set_title('RMSE vs K', fontsize=14, fontweight='bold')
        ax3.grid(True, alpha=0.3)
        
        # 4. Execution Time vs K
        ax4.plot(ks, times, 'o-', linewidth=2, markersize=8, color='#6A994E')
        ax4.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax4.set_ylabel('Execution Time (seconds)', fontsize=12)
        ax4.set_title('Execution Time vs K', fontsize=14, fontweight='bold')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        output_path = self.figures_dir / 'knn_k_value_analysis.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… KNN åˆ†æåœ–å·²ä¿å­˜: {output_path}")
        return True
    
    def generate_comparison_plot(self) -> bool:
        """ç”Ÿæˆéšæ®µå°æ¯”åœ–"""
        # æ‰¾å‡ºå„éšæ®µçš„æœ€ä½³é…ç½®
        stages = {}
        
        # è¼”åŠ©å‡½æ•¸ï¼šæ‰¾å‡ºéšæ®µæœ€ä½³é…ç½®
        def find_best_in_stage(stage_name: str):
            results = self.analyzer.load_stage_results(stage_name)
            if results:
                best = max(results, key=lambda x: x['data'].get('metrics', {}).get('hit_rate', 0))
                return best['config_name']
            return None
        
        # FILTER æœ€ä½³
        filter_best = find_best_in_stage('FILTER')
        if filter_best:
            stages['FILTER'] = filter_best
        
        # KNN_BASELINE æœ€ä½³
        knn_baseline_best = find_best_in_stage('KNN_BASELINE')
        if knn_baseline_best:
            stages['KNN_BASELINE'] = knn_baseline_best
        
        # SVD_KNN_GRID æœ€ä½³
        grid_results = self._load_grid_results()
        if grid_results:
            best_grid = max(grid_results, key=lambda x: x['hit_rate'])
            stages['SVD_KNN_GRID'] = best_grid['config_name']
        
        # BIAS æœ€ä½³
        bias_best = find_best_in_stage('BIAS')
        if bias_best:
            stages['BIAS'] = bias_best
        
        # OPT æœ€ä½³
        opt_best = find_best_in_stage('OPT')
        if opt_best:
            stages['OPT'] = opt_best
        
        stage_data = {}
        for stage, config in stages.items():
            data = self.analyzer.load_result(config)
            if data:
                metrics = data.get('metrics', {})
                stage_data[stage] = {
                    'hit_rate': metrics.get('hit_rate', 0),
                    'ndcg': metrics.get('ndcg', 0),
                }
        
        if not stage_data:
            print("âš ï¸ éšæ®µæ•¸æ“šä¸è¶³ï¼Œè·³éå°æ¯”åœ–ç”Ÿæˆ")
            return False
        
        # å‰µå»ºåœ–è¡¨
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        fig.suptitle('Best Configuration Comparison Across Stages', 
                     fontsize=16, fontweight='bold')
        
        stages_list = list(stage_data.keys())
        hit_rates = [stage_data[s]['hit_rate'] for s in stages_list]
        ndcgs = [stage_data[s]['ndcg'] for s in stages_list]
        
        x = np.arange(len(stages_list))
        width = 0.6
        
        # Hit Rate æ¯”è¼ƒ
        bars1 = ax1.bar(x, hit_rates, width, color='#2E86AB')
        ax1.set_xlabel('Stage', fontsize=12)
        ax1.set_ylabel('Hit Rate@10', fontsize=12)
        ax1.set_title('Hit Rate@10 Comparison', fontsize=14, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(stages_list)
        ax1.grid(True, alpha=0.3, axis='y')
        
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.4f}',
                    ha='center', va='bottom', fontsize=10)
        
        # NDCG æ¯”è¼ƒ
        bars2 = ax2.bar(x, ndcgs, width, color='#F18F01')
        ax2.set_xlabel('Stage', fontsize=12)
        ax2.set_ylabel('NDCG@10', fontsize=12)
        ax2.set_title('NDCG@10 Comparison', fontsize=14, fontweight='bold')
        ax2.set_xticks(x)
        ax2.set_xticklabels(stages_list)
        ax2.grid(True, alpha=0.3, axis='y')
        
        for bar in bars2:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.4f}',
                    ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        
        output_path = self.figures_dir / 'stage_comparison.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… éšæ®µå°æ¯”åœ–å·²ä¿å­˜: {output_path}")
        return True
    
    def generate_grid_heatmap(self) -> bool:
        """ç”Ÿæˆ SVDÃ—KNN ç¶²æ ¼æœç´¢ç†±åœ–"""
        grid_results = self._load_grid_results()
        
        if not grid_results:
            print("âš ï¸ SVD_KNN_GRID çµæœä¸è¶³ï¼Œè·³éç†±åœ–ç”Ÿæˆ")
            return False
        
        # æº–å‚™æ•¸æ“šçŸ©é™£
        svd_dims = sorted(set(r['n_components'] for r in grid_results))
        k_values = sorted(set(r['k_neighbors'] for r in grid_results))
        
        # å‰µå»ºç†±åœ–æ•¸æ“š
        hit_rate_matrix = np.zeros((len(svd_dims), len(k_values)))
        ndcg_matrix = np.zeros((len(svd_dims), len(k_values)))
        
        for result in grid_results:
            i = svd_dims.index(result['n_components'])
            j = k_values.index(result['k_neighbors'])
            hit_rate_matrix[i, j] = result['hit_rate']
            ndcg_matrix[i, j] = result['ndcg']
        
        # å‰µå»ºåœ–è¡¨
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))
        fig.suptitle('SVD Ã— KNN Grid Search Heatmap', fontsize=16, fontweight='bold')
        
        # Hit Rate ç†±åœ–
        im1 = ax1.imshow(hit_rate_matrix, cmap='YlOrRd', aspect='auto')
        ax1.set_xticks(range(len(k_values)))
        ax1.set_yticks(range(len(svd_dims)))
        ax1.set_xticklabels(k_values)
        ax1.set_yticklabels(svd_dims)
        ax1.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax1.set_ylabel('SVD Dimension', fontsize=12)
        ax1.set_title('Hit Rate@10', fontsize=14, fontweight='bold')
        
        # æ·»åŠ æ•¸å€¼æ¨™è¨»
        for i in range(len(svd_dims)):
            for j in range(len(k_values)):
                text = ax1.text(j, i, f'{hit_rate_matrix[i, j]:.3f}',
                               ha="center", va="center", color="black", fontsize=9)
        
        plt.colorbar(im1, ax=ax1, label='Hit Rate@10')
        
        # NDCG ç†±åœ–
        im2 = ax2.imshow(ndcg_matrix, cmap='YlGnBu', aspect='auto')
        ax2.set_xticks(range(len(k_values)))
        ax2.set_yticks(range(len(svd_dims)))
        ax2.set_xticklabels(k_values)
        ax2.set_yticklabels(svd_dims)
        ax2.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax2.set_ylabel('SVD Dimension', fontsize=12)
        ax2.set_title('NDCG@10', fontsize=14, fontweight='bold')
        
        # æ·»åŠ æ•¸å€¼æ¨™è¨»
        for i in range(len(svd_dims)):
            for j in range(len(k_values)):
                text = ax2.text(j, i, f'{ndcg_matrix[i, j]:.3f}',
                               ha="center", va="center", color="black", fontsize=9)
        
        plt.colorbar(im2, ax=ax2, label='NDCG@10')
        
        plt.tight_layout()
        
        output_path = self.figures_dir / 'svd_knn_grid_heatmap.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ç¶²æ ¼æœç´¢ç†±åœ–å·²ä¿å­˜: {output_path}")
        
        # ç”Ÿæˆåˆ†æå ±å‘Š
        best_result = max(grid_results, key=lambda x: x['hit_rate'])
        print(f"\nğŸ“Š ç¶²æ ¼æœç´¢åˆ†æ:")
        print(f"   æœ€ä½³é…ç½®: SVD={best_result['n_components']}, K={best_result['k_neighbors']}")
        print(f"   Hit Rate@10: {best_result['hit_rate']:.4f}")
        print(f"   NDCG@10: {best_result['ndcg']:.4f}")
        
        # åˆ†æè¶¨å‹¢
        print(f"\nğŸ” è¶¨å‹¢åˆ†æ:")
        
        # SVD ç¶­åº¦æ•ˆæœ
        svd_avg_hit_rates = [hit_rate_matrix[i, :].mean() for i in range(len(svd_dims))]
        svd_trend = "éå¢" if svd_avg_hit_rates[-1] > svd_avg_hit_rates[0] else "éæ¸›"
        print(f"   SVD ç¶­åº¦æ”¾å¤§æ•ˆæœ: {svd_trend}")
        print(f"   - ç¶­åº¦ {svd_dims[0]}: å¹³å‡ Hit Rate = {svd_avg_hit_rates[0]:.4f}")
        print(f"   - ç¶­åº¦ {svd_dims[-1]}: å¹³å‡ Hit Rate = {svd_avg_hit_rates[-1]:.4f}")
        
        # KNN Kå€¼æ•ˆæœ
        k_avg_hit_rates = [hit_rate_matrix[:, j].mean() for j in range(len(k_values))]
        k_trend = "éå¢" if k_avg_hit_rates[-1] > k_avg_hit_rates[0] else "éæ¸›"
        print(f"   KNN Kå€¼æ”¾å¤§æ•ˆæœ: {k_trend}")
        print(f"   - K={k_values[0]}: å¹³å‡ Hit Rate = {k_avg_hit_rates[0]:.4f}")
        print(f"   - K={k_values[-1]}: å¹³å‡ Hit Rate = {k_avg_hit_rates[-1]:.4f}")
        
        # å»ºè­°
        print(f"\nğŸ’¡ å»ºè­°:")
        if svd_avg_hit_rates[-1] > svd_avg_hit_rates[0] and (svd_avg_hit_rates[-1] - svd_avg_hit_rates[-2]) > 0.001:
            print(f"   âš ï¸  SVD ç¶­åº¦ä»åœ¨æ”¹å–„ï¼Œå»ºè­°æ¸¬è©¦æ›´å¤§çš„ç¶­åº¦ï¼ˆå¦‚ 512, 1024ï¼‰")
        else:
            print(f"   âœ… SVD ç¶­åº¦å·²é”æ”¶æ–‚ï¼Œç•¶å‰ç¯„åœå·²è¶³å¤ ")
        
        if k_avg_hit_rates[-1] > k_avg_hit_rates[0] and (k_avg_hit_rates[-1] - k_avg_hit_rates[-2]) > 0.001:
            print(f"   âš ï¸  KNN Kå€¼ä»åœ¨æ”¹å–„ï¼Œå»ºè­°æ¸¬è©¦æ›´å¤§çš„ K å€¼ï¼ˆå¦‚ 128, 256ï¼‰")
        else:
            print(f"   âœ… KNN Kå€¼å·²é”æ”¶æ–‚ï¼Œç•¶å‰ç¯„åœå·²è¶³å¤ ")
        
        return True
    
    def generate_expand_heatmap(self) -> bool:
        """ç”Ÿæˆ SVD_KNN_EXPAND æ“´å±•ç¶²æ ¼æœç´¢ç†±åœ–"""
        expand_results = self._load_expand_results()
        
        if not expand_results:
            print("âš ï¸ SVD_KNN_EXPAND çµæœä¸è¶³ï¼Œè·³éç†±åœ–ç”Ÿæˆ")
            return False
        
        # æº–å‚™æ•¸æ“šçŸ©é™£
        svd_dims = sorted(set(r['n_components'] for r in expand_results))
        k_values = sorted(set(r['k_neighbors'] for r in expand_results))
        
        # å‰µå»ºç†±åœ–æ•¸æ“š
        hit_rate_matrix = np.zeros((len(svd_dims), len(k_values)))
        ndcg_matrix = np.zeros((len(svd_dims), len(k_values)))
        
        for result in expand_results:
            i = svd_dims.index(result['n_components'])
            j = k_values.index(result['k_neighbors'])
            hit_rate_matrix[i, j] = result['hit_rate']
            ndcg_matrix[i, j] = result['ndcg']
        
        # å‰µå»ºåœ–è¡¨
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
        fig.suptitle('SVD Ã— KNN Expand Grid Search Heatmap', fontsize=16, fontweight='bold')
        
        # Hit Rate ç†±åœ–
        im1 = ax1.imshow(hit_rate_matrix, cmap='YlOrRd', aspect='auto')
        ax1.set_xticks(range(len(k_values)))
        ax1.set_yticks(range(len(svd_dims)))
        ax1.set_xticklabels(k_values)
        ax1.set_yticklabels(svd_dims)
        ax1.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax1.set_ylabel('SVD Dimension', fontsize=12)
        ax1.set_title('Hit Rate@10', fontsize=14, fontweight='bold')
        
        # æ·»åŠ æ•¸å€¼æ¨™è¨»
        for i in range(len(svd_dims)):
            for j in range(len(k_values)):
                text = ax1.text(j, i, f'{hit_rate_matrix[i, j]:.3f}',
                               ha="center", va="center", color="black", fontsize=9)
        
        plt.colorbar(im1, ax=ax1, label='Hit Rate@10')
        
        # NDCG ç†±åœ–
        im2 = ax2.imshow(ndcg_matrix, cmap='YlGnBu', aspect='auto')
        ax2.set_xticks(range(len(k_values)))
        ax2.set_yticks(range(len(svd_dims)))
        ax2.set_xticklabels(k_values)
        ax2.set_yticklabels(svd_dims)
        ax2.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax2.set_ylabel('SVD Dimension', fontsize=12)
        ax2.set_title('NDCG@10', fontsize=14, fontweight='bold')
        
        # æ·»åŠ æ•¸å€¼æ¨™è¨»
        for i in range(len(svd_dims)):
            for j in range(len(k_values)):
                text = ax2.text(j, i, f'{ndcg_matrix[i, j]:.3f}',
                               ha="center", va="center", color="black", fontsize=9)
        
        plt.colorbar(im2, ax=ax2, label='NDCG@10')
        
        plt.tight_layout()
        
        output_path = self.figures_dir / 'svd_knn_expand_heatmap.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… æ“´å±•ç¶²æ ¼æœç´¢ç†±åœ–å·²ä¿å­˜: {output_path}")
        
        # ç”Ÿæˆåˆ†æå ±å‘Š
        best_result = max(expand_results, key=lambda x: x['hit_rate'])
        print(f"\nğŸ“Š æ“´å±•ç¶²æ ¼æœç´¢åˆ†æ:")
        print(f"   æœ€ä½³é…ç½®: SVD={best_result['n_components']}, K={best_result['k_neighbors']}")
        print(f"   Hit Rate@10: {best_result['hit_rate']:.4f}")
        print(f"   NDCG@10: {best_result['ndcg']:.4f}")
        
        return True
    
    def generate_svd_vs_baseline_comparison(self) -> bool:
        """ç”Ÿæˆæœ‰ç„¡ SVD å°æ¯”åœ–ï¼šç´”KNN vs SVD+KNN"""
        baseline_results = self._load_knn_baseline_results()
        grid_results = self._load_grid_results()
        
        if not baseline_results:
            print("âš ï¸ KNN_BASELINE çµæœä¸è¶³ï¼Œè·³éå°æ¯”åœ–ç”Ÿæˆ")
            return False
        
        if not grid_results:
            print("âš ï¸ SVD_KNN_GRID çµæœä¸è¶³ï¼Œè·³éå°æ¯”åœ–ç”Ÿæˆ")
            return False
        
        # å°æ–¼æ¯å€‹ K å€¼ï¼Œæ‰¾å‡º SVD+KNN çš„æœ€ä½³çµæœ
        svd_knn_by_k = {}
        for result in grid_results:
            k = result['k_neighbors']
            if k not in svd_knn_by_k or result['hit_rate'] > svd_knn_by_k[k]['hit_rate']:
                svd_knn_by_k[k] = result
        
        # åªæ¯”è¼ƒå…©è€…éƒ½æœ‰çš„ K å€¼
        baseline_by_k = {r['k_neighbors']: r for r in baseline_results}
        common_ks = sorted(set(baseline_by_k.keys()) & set(svd_knn_by_k.keys()))
        
        if not common_ks:
            print("âš ï¸ æ²’æœ‰å…±åŒçš„ K å€¼å¯ä¾›æ¯”è¼ƒ")
            return False
        
        # æº–å‚™æ•¸æ“š
        baseline_hit_rates = [baseline_by_k[k]['hit_rate'] for k in common_ks]
        baseline_ndcgs = [baseline_by_k[k]['ndcg'] for k in common_ks]
        baseline_times = [baseline_by_k[k]['total_time'] for k in common_ks]
        
        svd_hit_rates = [svd_knn_by_k[k]['hit_rate'] for k in common_ks]
        svd_ndcgs = [svd_knn_by_k[k]['ndcg'] for k in common_ks]
        svd_times = [svd_knn_by_k[k]['total_time'] for k in common_ks]
        svd_dims = [svd_knn_by_k[k]['n_components'] for k in common_ks]
        
        # å‰µå»ºåœ–è¡¨
        fig = plt.figure(figsize=(18, 12))
        gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)
        
        fig.suptitle('Pure KNN vs SVD+KNN Comparison', fontsize=18, fontweight='bold')
        
        # 1. Hit Rate æ¯”è¼ƒï¼ˆæŠ˜ç·šåœ–ï¼‰
        ax1 = fig.add_subplot(gs[0, 0])
        ax1.plot(common_ks, baseline_hit_rates, 'o-', linewidth=2, markersize=8, 
                color='#E63946', label='Pure KNN (no SVD)')
        ax1.plot(common_ks, svd_hit_rates, 's-', linewidth=2, markersize=8, 
                color='#2E86AB', label='SVD+KNN (best SVD dim per K)')
        ax1.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax1.set_ylabel('Hit Rate@10', fontsize=12)
        ax1.set_title('Hit Rate@10: Pure KNN vs SVD+KNN', fontsize=14, fontweight='bold')
        ax1.legend(fontsize=10)
        ax1.grid(True, alpha=0.3)
        
        # 2. NDCG æ¯”è¼ƒï¼ˆæŠ˜ç·šåœ–ï¼‰
        ax2 = fig.add_subplot(gs[0, 1])
        ax2.plot(common_ks, baseline_ndcgs, 'o-', linewidth=2, markersize=8, 
                color='#E63946', label='Pure KNN')
        ax2.plot(common_ks, svd_ndcgs, 's-', linewidth=2, markersize=8, 
                color='#2E86AB', label='SVD+KNN')
        ax2.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax2.set_ylabel('NDCG@10', fontsize=12)
        ax2.set_title('NDCG@10: Pure KNN vs SVD+KNN', fontsize=14, fontweight='bold')
        ax2.legend(fontsize=10)
        ax2.grid(True, alpha=0.3)
        
        # 3. æ”¹å–„ç™¾åˆ†æ¯”ï¼ˆæŸ±ç‹€åœ–ï¼‰
        ax3 = fig.add_subplot(gs[1, 0])
        improvements = [(svd - base) / base * 100 if base > 0 else 0 
                       for base, svd in zip(baseline_hit_rates, svd_hit_rates)]
        colors = ['#06D6A0' if imp > 0 else '#EF476F' for imp in improvements]
        bars = ax3.bar(range(len(common_ks)), improvements, color=colors, alpha=0.7, edgecolor='black')
        ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.8)
        ax3.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax3.set_ylabel('Improvement (%)', fontsize=12)
        ax3.set_title('SVD Improvement over Pure KNN (Hit Rate@10)', fontsize=14, fontweight='bold')
        ax3.set_xticks(range(len(common_ks)))
        ax3.set_xticklabels(common_ks)
        ax3.grid(True, alpha=0.3, axis='y')
        
        # æ¨™è¨»æ•¸å€¼
        for i, (bar, imp) in enumerate(zip(bars, improvements)):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{imp:+.1f}%',
                    ha='center', va='bottom' if height > 0 else 'top', fontsize=9)
        
        # 4. åŸ·è¡Œæ™‚é–“æ¯”è¼ƒï¼ˆæŸ±ç‹€åœ–ï¼‰
        ax4 = fig.add_subplot(gs[1, 1])
        x = np.arange(len(common_ks))
        width = 0.35
        bars1 = ax4.bar(x - width/2, baseline_times, width, label='Pure KNN', 
                       color='#E63946', alpha=0.7, edgecolor='black')
        bars2 = ax4.bar(x + width/2, svd_times, width, label='SVD+KNN', 
                       color='#2E86AB', alpha=0.7, edgecolor='black')
        ax4.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax4.set_ylabel('Execution Time (seconds)', fontsize=12)
        ax4.set_title('Execution Time: Pure KNN vs SVD+KNN', fontsize=14, fontweight='bold')
        ax4.set_xticks(x)
        ax4.set_xticklabels(common_ks)
        ax4.legend(fontsize=10)
        ax4.grid(True, alpha=0.3, axis='y')
        
        # 5. æœ€ä½³ SVD ç¶­åº¦åˆ†å¸ƒï¼ˆæŸ±ç‹€åœ–ï¼‰
        ax5 = fig.add_subplot(gs[2, 0])
        ax5.bar(range(len(common_ks)), svd_dims, color='#F77F00', alpha=0.7, edgecolor='black')
        ax5.set_xlabel('K (Number of Neighbors)', fontsize=12)
        ax5.set_ylabel('Best SVD Dimension', fontsize=12)
        ax5.set_title('Optimal SVD Dimension for Each K', fontsize=14, fontweight='bold')
        ax5.set_xticks(range(len(common_ks)))
        ax5.set_xticklabels(common_ks)
        ax5.grid(True, alpha=0.3, axis='y')
        
        # æ¨™è¨»ç¶­åº¦å€¼
        for i, dim in enumerate(svd_dims):
            ax5.text(i, dim, f'{dim}', ha='center', va='bottom', fontsize=9)
        
        # 6. æ‘˜è¦çµ±è¨ˆè¡¨æ ¼
        ax6 = fig.add_subplot(gs[2, 1])
        ax6.axis('off')
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        avg_improvement = np.mean(improvements)
        max_improvement = max(improvements)
        max_imp_k = common_ks[improvements.index(max_improvement)]
        
        avg_baseline_hit = np.mean(baseline_hit_rates)
        avg_svd_hit = np.mean(svd_hit_rates)
        
        avg_baseline_time = np.mean(baseline_times)
        avg_svd_time = np.mean(svd_times)
        time_overhead = (avg_svd_time - avg_baseline_time) / avg_baseline_time * 100 if avg_baseline_time > 0 else 0
        
        summary_text = f"""
        ğŸ“Š Summary Statistics
        
        Performance (Hit Rate@10):
        â€¢ Pure KNN Average: {avg_baseline_hit:.4f}
        â€¢ SVD+KNN Average: {avg_svd_hit:.4f}
        â€¢ Average Improvement: {avg_improvement:+.2f}%
        â€¢ Max Improvement: {max_improvement:+.2f}% (at K={max_imp_k})
        
        Efficiency (Execution Time):
        â€¢ Pure KNN Average: {avg_baseline_time:.1f}s
        â€¢ SVD+KNN Average: {avg_svd_time:.1f}s
        â€¢ Time Overhead: {time_overhead:+.1f}%
        
        Conclusion:
        {'âœ… SVD brings significant improvement!' if avg_improvement > 1 else 'âš ï¸ SVD improvement is marginal'}
        {'â±ï¸ Acceptable time overhead' if time_overhead < 50 else 'âš ï¸ Significant time cost'}
        """
        
        ax6.text(0.1, 0.9, summary_text, transform=ax6.transAxes, 
                fontsize=11, verticalalignment='top', family='monospace',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
        
        plt.tight_layout()
        
        output_path = self.figures_dir / 'svd_vs_baseline_comparison.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… SVD vs Baseline å°æ¯”åœ–å·²ä¿å­˜: {output_path}")
        
        # è¼¸å‡ºè©³ç´°åˆ†æ
        print(f"\nğŸ“Š SVD vs Pure KNN è©³ç´°åˆ†æ:")
        print(f"   å¹³å‡æ”¹å–„: {avg_improvement:+.2f}%")
        print(f"   æœ€å¤§æ”¹å–„: {max_improvement:+.2f}% (K={max_imp_k})")
        print(f"   æ™‚é–“é–‹éŠ·: {time_overhead:+.1f}%")
        
        if avg_improvement > 5:
            print(f"   ğŸ’¡ çµè«–: SVD å¸¶ä¾†é¡¯è‘—æ•ˆèƒ½æå‡ï¼Œå€¼å¾—ä½¿ç”¨ï¼")
        elif avg_improvement > 1:
            print(f"   ğŸ’¡ çµè«–: SVD æœ‰è¼•å¾®æ”¹å–„ï¼Œå¯è€ƒæ…®ä½¿ç”¨")
        else:
            print(f"   ğŸ’¡ çµè«–: SVD æ”¹å–„ä¸æ˜é¡¯ï¼Œç´”KNNå¯èƒ½æ›´å¯¦ç”¨")
        
        return True
    
    def generate_dataset_plots(self, use_full_dataset: bool = False) -> bool:
        """ç”Ÿæˆè³‡æ–™é›†åˆ†æåœ–è¡¨
        
        Args:
            use_full_dataset: æ˜¯å¦ä½¿ç”¨å®Œæ•´è³‡æ–™é›†ï¼ˆ20M è©•åˆ†ï¼‰ï¼Œä½¿ç”¨åˆ†æ‰¹è™•ç†é¿å…è¨˜æ†¶é«”æº¢å‡º
        """
        # ç¢ºå®šæ–‡ä»¶åå¾Œç¶´
        suffix = f"_{self.dataset_size}" if self.dataset_size else ""
        
        # æª¢æŸ¥æ‰€æœ‰è³‡æ–™é›†åœ–è¡¨æ˜¯å¦å·²å­˜åœ¨
        required_plots = [
            f'data_rating_distribution{suffix}.png',
            f'data_user_activity_long_tail{suffix}.png',
            f'data_movie_popularity_long_tail{suffix}.png'
        ]
        
        all_exist = all((self.figures_dir / plot).exists() for plot in required_plots)
        if all_exist:
            print(f"âœ… è³‡æ–™é›†åœ–è¡¨å·²å­˜åœ¨ï¼ˆ{self.dataset_size or 'sample'}ï¼‰ï¼Œè·³éç”Ÿæˆ")
            return True
        
        # 1. è©•åˆ†åˆ†å¸ƒåœ– - ä½¿ç”¨åˆ†æ‰¹è™•ç†
        print("ğŸ“Š ç”Ÿæˆè©•åˆ†åˆ†å¸ƒåœ–...")
        rating_stats = self.dataset_analyzer.analyze_rating_distribution(use_full_dataset=use_full_dataset)
        
        if rating_stats is None:
            print("âš ï¸ ç„¡æ³•è¼‰å…¥è³‡æ–™ï¼Œè·³éè³‡æ–™é›†åœ–è¡¨ç”Ÿæˆ")
            return False
        
        plt.figure(figsize=(12, 6))
        
        # ç¢ºä¿é¡¯ç¤ºæ‰€æœ‰å¯èƒ½çš„è©•åˆ†å€¼ (0.5 éå¢)
        all_ratings = [0.5 * i for i in range(1, 11)]  # 0.5, 1.0, 1.5, ..., 5.0
        rating_dist = rating_stats['distribution']
        counts = [rating_dist.get(r, 0) for r in all_ratings]
        
        bars = plt.bar(all_ratings, counts, width=0.4,
                      color='#2E86AB', alpha=0.8, edgecolor='black')
        plt.xlabel('Rating (Stars)', fontsize=12)
        plt.ylabel('Count', fontsize=12)
        
        # æ¨™é¡Œé¡¯ç¤ºç¸½è©•åˆ†æ•¸
        total = rating_stats['total_ratings']
        plt.title(f'Rating Distribution (Total: {total:,} ratings)', 
                 fontsize=14, fontweight='bold')
        plt.xticks(all_ratings)
        plt.grid(True, alpha=0.3, axis='y')
        plt.ylim(bottom=0)
        
        # æ¨™è¨»æ•¸å€¼ï¼ˆåªæ¨™è¨»éé›¶çš„ï¼‰
        for bar, count in zip(bars, counts):
            if count > 0:
                height = bar.get_height()
                plt.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(count):,}',
                        ha='center', va='bottom', fontsize=9)
        
        plt.tight_layout()
        output_path = self.figures_dir / f'data_rating_distribution{suffix}.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… è©•åˆ†åˆ†å¸ƒåœ–å·²ä¿å­˜: {output_path}")
        
        # 2. ä½¿ç”¨è€…æ´»èºåº¦é•·å°¾åœ– - ä½¿ç”¨åˆ†æ‰¹è™•ç†
        print("ğŸ“Š ç”Ÿæˆä½¿ç”¨è€…æ´»èºåº¦é•·å°¾åœ–...")
        user_stats = self.dataset_analyzer.analyze_user_activity(use_full_dataset=use_full_dataset, top_n=10000)
        
        if user_stats is None:
            return False
        
        plt.figure(figsize=(12, 6))
        user_counts = user_stats.get('_plot_data', [])
        
        if len(user_counts) > 0:
            plt.plot(range(len(user_counts)), user_counts, color='#2E86AB', linewidth=1.5)
            plt.fill_between(range(len(user_counts)), user_counts, color='#2E86AB', alpha=0.2)
        plt.xlabel('User (sorted by activity)', fontsize=12)
        plt.ylabel('Number of Ratings', fontsize=12)
        
        # æ¨™é¡Œé¡¯ç¤ºç¸½ç”¨æˆ¶æ•¸
        total_users = user_stats['total_users']
        plt.title(f'User Activity Long Tail (Total: {total_users:,} users)', 
                 fontsize=14, fontweight='bold')
        plt.xlim(0, min(len(user_counts), 5000))  # é¡¯ç¤ºå‰ 5000 å€‹ç”¨æˆ¶
        plt.ylim(bottom=0)
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        output_path = self.figures_dir / f'data_user_activity_long_tail{suffix}.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… ä½¿ç”¨è€…æ´»èºåº¦åœ–å·²ä¿å­˜: {output_path}")
        
        # 3. é›»å½±æµè¡Œåº¦é•·å°¾åœ– - ä½¿ç”¨åˆ†æ‰¹è™•ç†
        print("ğŸ“Š ç”Ÿæˆé›»å½±æµè¡Œåº¦é•·å°¾åœ–...")
        item_stats = self.dataset_analyzer.analyze_item_popularity(use_full_dataset=use_full_dataset, top_n=10000)
        
        if item_stats is None:
            return False
        
        plt.figure(figsize=(12, 6))
        item_counts = item_stats.get('_plot_data', [])
        
        if len(item_counts) > 0:
            plt.plot(range(len(item_counts)), item_counts, color='#F18F01', linewidth=1.5)
            plt.fill_between(range(len(item_counts)), item_counts, color='#F18F01', alpha=0.2)
        plt.xlabel('Movie (sorted by popularity)', fontsize=12)
        plt.ylabel('Number of Ratings', fontsize=12)
        
        # æ¨™é¡Œé¡¯ç¤ºç¸½é›»å½±æ•¸
        total_items = item_stats['total_items']
        plt.title(f'Movie Popularity Long Tail (Total: {total_items:,} movies)', 
                 fontsize=14, fontweight='bold')
        plt.xlim(0, min(len(item_counts), 5000))  # é¡¯ç¤ºå‰ 5000 éƒ¨é›»å½±
        plt.ylim(bottom=0)
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        output_path = self.figures_dir / f'data_movie_popularity_long_tail{suffix}.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… é›»å½±æµè¡Œåº¦åœ–å·²ä¿å­˜: {output_path}")
        
        return True
    
    def generate_summary_table(self) -> str:
        """ç”Ÿæˆæ‘˜è¦è¡¨æ ¼ï¼ˆMarkdown æ ¼å¼ï¼‰"""
        summary = self.analyzer.generate_summary_table()
        
        if not summary:
            return "No results available."
        
        lines = [
            "# å¯¦é©—çµæœæ‘˜è¦\n",
            "| éšæ®µ | æœ€ä½³é…ç½® | Hit Rate@10 | NDCG@10 | RMSE | é…ç½®æ•¸ |",
            "|------|---------|------------|---------|------|--------|"
        ]
        
        for row in summary:
            lines.append(
                f"| {row['stage']} | {row['best_config']} | "
                f"{row['hit_rate']:.4f} | {row['ndcg']:.4f} | "
                f"{row['rmse']:.4f} | {row['count']} |"
            )
        
        return "\n".join(lines)
    
    def generate_full_report(self, include_dataset_analysis: bool = True, use_full_dataset: bool = False) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´å ±å‘Š
        
        Args:
            include_dataset_analysis: æ˜¯å¦åŒ…å«è³‡æ–™é›†åˆ†æ
            use_full_dataset: æ˜¯å¦ä½¿ç”¨å®Œæ•´è³‡æ–™é›†ï¼ˆ20M è©•åˆ†ï¼‰é€²è¡Œåˆ†æ
        """
        print("=" * 80)
        print("ğŸ“Š ç”Ÿæˆå®Œæ•´å¯¦é©—å ±å‘Š")
        if use_full_dataset:
            print("âš ï¸  ä½¿ç”¨å®Œæ•´è³‡æ–™é›†ï¼ˆ20M è©•åˆ†ï¼‰- é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“")
        print("=" * 80)
        print()
        
        results = {
            'progress': self.analyzer.check_progress(),
            'plots': {},
            'summary_table': None,
            'dataset_analysis': None
        }
        
        # è³‡æ–™é›†åˆ†æï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if include_dataset_analysis:
            # ç¢ºå®šçµ±è¨ˆæ–‡ä»¶å
            suffix = f"_{self.dataset_size}" if self.dataset_size else ""
            stats_file = self.output_dir / f'dataset_statistics{suffix}.json'
            
            # æª¢æŸ¥çµ±è¨ˆæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if stats_file.exists():
                print(f"âœ… è³‡æ–™é›†çµ±è¨ˆå·²å­˜åœ¨ï¼ˆ{self.dataset_size or 'sample'}ï¼‰ï¼Œè·³éåˆ†æ")
                results['dataset_analysis'] = str(stats_file)
            else:
                if use_full_dataset:
                    print("ğŸ“Š åˆ†æå®Œæ•´è³‡æ–™é›†çµ±è¨ˆç‰¹å¾µï¼ˆä½¿ç”¨åˆ†æ‰¹è™•ç†ï¼‰...")
                else:
                    print("ğŸ“Š åˆ†æè³‡æ–™é›†çµ±è¨ˆç‰¹å¾µï¼ˆä½¿ç”¨æ¨£æœ¬ï¼‰...")
                dataset_stats = self.dataset_analyzer.generate_full_analysis()
                if dataset_stats:
                    # éæ¿¾æ‰ä¸èƒ½åºåˆ—åŒ–çš„å­—æ®µï¼ˆä»¥ _ é–‹é ­çš„å…§éƒ¨æ•¸æ“šï¼‰
                    def filter_internal_fields(obj):
                        if isinstance(obj, dict):
                            return {k: filter_internal_fields(v) 
                                   for k, v in obj.items() 
                                   if isinstance(k, str) and not k.startswith('_')}
                        elif isinstance(obj, list):
                            return [filter_internal_fields(item) for item in obj]
                        else:
                            return obj
                    
                    clean_stats = filter_internal_fields(dataset_stats)
                    
                    # ä¿å­˜çµ±è¨ˆè³‡æ–™
                    with open(stats_file, 'w', encoding='utf-8') as f:
                        json.dump(clean_stats, f, indent=2, ensure_ascii=False)
                    results['dataset_analysis'] = str(stats_file)
                    print(f"âœ… è³‡æ–™é›†çµ±è¨ˆå·²ä¿å­˜: {stats_file}")
            print()
            
            # ç”Ÿæˆè³‡æ–™é›†åœ–è¡¨
            print("ğŸ“ˆ ç”Ÿæˆè³‡æ–™é›†å¯è¦–åŒ–åœ–è¡¨...")
            results['plots']['dataset'] = self.generate_dataset_plots(use_full_dataset=use_full_dataset)
            print()
        
        # ç”Ÿæˆå¯¦é©—çµæœå¯è¦–åŒ–åœ–è¡¨
        print("ğŸ“ˆ ç”Ÿæˆå¯¦é©—çµæœå¯è¦–åŒ–åœ–è¡¨...")
        results['plots']['grid_heatmap'] = self.generate_grid_heatmap()
        results['plots']['expand_heatmap'] = self.generate_expand_heatmap()
        print()
        results['plots']['svd'] = self.generate_svd_plots()
        results['plots']['knn'] = self.generate_knn_plots()
        results['plots']['comparison'] = self.generate_comparison_plot()
        print()
        
        # ç”Ÿæˆæ‘˜è¦è¡¨æ ¼
        print("ğŸ“‹ ç”Ÿæˆæ‘˜è¦è¡¨æ ¼...")
        summary_md = self.generate_summary_table()
        summary_file = self.output_dir / 'summary.md'
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary_md)
        results['summary_table'] = str(summary_file)
        print(f"âœ… æ‘˜è¦è¡¨æ ¼å·²ä¿å­˜: {summary_file}")
        print()
        
        # ä¿å­˜æœ€ä½³é…ç½®
        print("ğŸ† æå–æœ€ä½³é…ç½®...")
        best_configs = self.analyzer.get_best_configs()
        if best_configs:
            best_file = self.output_dir / 'best_configs.json'
            with open(best_file, 'w', encoding='utf-8') as f:
                json.dump(best_configs, f, indent=2, ensure_ascii=False)
            print(f"âœ… æœ€ä½³é…ç½®å·²ä¿å­˜: {best_file}")
        print()
        
        print("=" * 80)
        print("âœ¨ å ±å‘Šç”Ÿæˆå®Œæˆï¼")
        print("=" * 80)
        print()
        print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {self.output_dir}/")
        
        # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
        plot_files = [
            "figures/svd_knn_grid_heatmap.png",
            "figures/svd_dimension_analysis.png",
            "figures/knn_k_value_analysis.png",
            "figures/svd_vs_baseline_comparison.png",
            "figures/stage_comparison.png"
        ]
        
        if include_dataset_analysis:
            plot_files.extend([
                "figures/data_rating_distribution.png",
                "figures/data_user_activity_long_tail.png",
                "figures/data_movie_popularity_long_tail.png"
            ])
        
        for plot_file in plot_files:
            if (self.output_dir / plot_file.replace('figures/', 'figures/')).exists():
                print(f"   - {plot_file}")
        
        print(f"   - summary.md")
        print(f"   - best_configs.json")
        if include_dataset_analysis:
            print(f"   - dataset_statistics.json")
        print()
        
        return results


def generate_report(log_dir: str = 'log', output_dir: str = 'reports', 
                   include_dataset_analysis: bool = True, use_full_dataset: bool = False,
                   sample_size: int = None):
    """ç”Ÿæˆå®Œæ•´å ±å‘Šï¼ˆä¾¿æ·å‡½æ•¸ï¼‰
    
    Args:
        log_dir: å¯¦é©—æ—¥èªŒç›®éŒ„
        output_dir: å ±å‘Šè¼¸å‡ºç›®éŒ„
        include_dataset_analysis: æ˜¯å¦åŒ…å«è³‡æ–™é›†åˆ†æ
        use_full_dataset: æ˜¯å¦ä½¿ç”¨å®Œæ•´è³‡æ–™é›†ï¼ˆ20M è©•åˆ†ï¼‰
        sample_size: æ¨£æœ¬å¤§å°ï¼ˆå¦‚æœä¸ä½¿ç”¨å®Œæ•´è³‡æ–™é›†ï¼‰
    """
    # ç¢ºå®šè³‡æ–™é›†å¤§å°æ¨™è­˜
    if use_full_dataset:
        dataset_size = 'full'
    elif sample_size:
        dataset_size = str(sample_size)
    else:
        dataset_size = None
    
    analyzer = ExperimentAnalyzer(log_dir=log_dir)
    dataset_analyzer = DatasetAnalyzer()
    generator = ReportGenerator(
        analyzer=analyzer,
        dataset_analyzer=dataset_analyzer,
        output_dir=output_dir,
        dataset_size=dataset_size
    )
    return generator.generate_full_report(
        include_dataset_analysis=include_dataset_analysis,
        use_full_dataset=use_full_dataset
    )


# å‘½ä»¤è¡Œæ¥å£
if __name__ == "__main__":
    generate_report()
